---
title: Infrastructure
index: 1
---

# Infrastructure Architecture

The infrastructure is based on top of Kubernetes<sup>®</sup> using Tekton<sup>®</sup> TaskRuns, ConfigMaps, Secrets, and Persistent Volumes. See the [Task architecture](/docs/boomerang-flow/architecture/tasks) for more information.

## Kubernetes

### TaskRuns

Tekon TaskRuns are a Custom Resource Definition (CRD) wrapping Kubernetes Pods and allow us to define the Task specific metadata.

A certain amount of disk, memory, and CPU is required to process TaskRuns. Our recommendation is to run these on dedicated nodes and to set them to automatically delete. This will ensure you have enough resources to continually execute new Tasks.

### Nodes

The Workflow Tasks run as jobs on any node, unless dedicated nodes are implemented using:

- Node taint: `dedicated=bmrg-worker:NoSchedule`
- Node label: `node-role.kubernetes.io/bmrg-worker=true`

### Ephemeral storage

As with all containers, there is ephemeral storage used that we have limited to 8GB by default. This impacts the number of Tasks that can be running in parallel, based on the amount of primary disk used. This is important.

Flow Tasks have a setting to delete on completion. If this is not enabled, then the completed workers stick around and use up the available ephemeral storage.

See [Kubernetes ephemeral storage](https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#local-ephemeral-storage) reference information.

### Persistent volumes

There are different types of persistent volumes used by the task orchestration system and are enabled by Workflow in the Workflow Editor > Configuration.

You can configure the storage size, storage class, and access modes for the following types in the Settings under Administer. By default:
- Storage Size is set to 1GB
- Storage Class is not set. This will therefore use the default defined in your kubernetes cluster
- Access Mode is set as Read Write Many.

We recommend using [Ranchers Local Path Provisioner](https://github.com/rancher/local-path-provisioner) on the nodes executing Tasks as this allows for dynamic provisioning of local disk, that if SSD, allows for low latency high speed writes.

#### Workspaces

The workspaces persistent volume is still an *alpha* feature and can only be spun up via the internal legacy APIs and can be used as a persistent cache between executions. Whilst these do not churn nearly as often, they do add up i.e. if you have 100 workflows you will have a requirement of 100GB (100 x xGB) of Persistent Storage available.

This is mapped to the `/workspace` mounted storage in the Tasks in a Workflow.

#### Workflows

The workflows persistent volume is per workflow execution and is used as a per execution storage. This can cause quite a churn of persistent volumes and can cause instability depending on the Storage driver you are using.

This is mapped to the `/workflow` mounted storage in the Tasks in a Workflow.

### Pod Anti-affinity

If dedicated nodes are enabled, a pod-soft anti-affinity feature is also enabled to ensure that attempts are made to balance workers across nodes as best as possible.
